{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ğŸ“ˆ Google (GOOGL) Stock Price Prediction with Advanced ML Models\n",
    "\n",
    "## ğŸ¯ Objective\n",
    "Predict Google stock prices using **7 different machine learning models** and provide **clear BUY/SELL recommendations** for paper trading.\n",
    "\n",
    "### Features:\n",
    "- âœ… **10 Years of Historical Data** for maximum accuracy\n",
    "- âœ… **7+ ML Models** (Linear, Ridge, Lasso, Random Forest, XGBoost, Gradient Boosting, Extra Trees, SVR)\n",
    "- âœ… **40+ Technical Indicators** (SMA, EMA, RSI, MACD, Bollinger Bands, etc.)\n",
    "- âœ… **Ensemble Predictions** (weighted average of all models)\n",
    "- âœ… **Buy/Sell Signal Generation** with confidence scores\n",
    "- âœ… **Paper Trading Ready** recommendations\n",
    "- âœ… **Comprehensive Visualizations**\n",
    "\n",
    "âš ï¸ **DISCLAIMER**: This is for educational and paper trading purposes only. Not financial advice!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# ML models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Project modules\n",
    "from data_collector import StockDataCollector\n",
    "from feature_engineering import FeatureEngineer\n",
    "from visualizer import StockVisualizer\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"ğŸ“… Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock configuration\n",
    "TICKER = 'GOOGL'  # Google stock\n",
    "PERIOD = '10y'    # 10 years of data for maximum accuracy\n",
    "TEST_SIZE = 0.2   # 20% for testing\n",
    "\n",
    "# Model configuration\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 200  # More trees for better accuracy\n",
    "\n",
    "# Trading signal configuration\n",
    "BUY_THRESHOLD = 0.02   # 2% predicted increase = BUY signal\n",
    "SELL_THRESHOLD = -0.01 # 1% predicted decrease = SELL signal\n",
    "CONFIDENCE_THRESHOLD = 0.7  # 70% model agreement required\n",
    "\n",
    "print(f\"ğŸ¯ Target Stock: {TICKER}\")\n",
    "print(f\"ğŸ“Š Data Period: {PERIOD}\")\n",
    "print(f\"ğŸ¤– Number of Estimators: {N_ESTIMATORS}\")\n",
    "print(f\"ğŸ“ˆ Buy Threshold: {BUY_THRESHOLD*100}%\")\n",
    "print(f\"ğŸ“‰ Sell Threshold: {SELL_THRESHOLD*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_collection",
   "metadata": {},
   "source": [
    "## 3. Data Collection\n",
    "\n",
    "Fetching 10 years of Google stock data for maximum prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fetch_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data collector\n",
    "collector = StockDataCollector(data_dir='../data')\n",
    "\n",
    "# Fetch Google stock data\n",
    "print(f\"ğŸ“¥ Fetching {TICKER} data for {PERIOD}...\")\n",
    "df = collector.fetch_stock_data(TICKER, period=PERIOD)\n",
    "\n",
    "print(f\"\\nâœ… Data loaded successfully!\")\n",
    "print(f\"ğŸ“Š Shape: {df.shape}\")\n",
    "print(f\"ğŸ“… Date Range: {df.index[0]} to {df.index[-1]}\")\n",
    "print(f\"ğŸ’° Latest Close Price: ${df['Close'].iloc[-1]:.2f}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock_info",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stock information\n",
    "info = collector.get_stock_info(TICKER)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ“Š {TICKER} - COMPANY INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "for key, value in info.items():\n",
    "    print(f\"  {key.replace('_', ' ').title()}: {value}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"ğŸ“Š Statistical Summary:\\n\")\n",
    "print(df.describe())\n",
    "\n",
    "# Price statistics\n",
    "print(f\"\\nğŸ’° Price Statistics:\")\n",
    "print(f\"  All-Time High: ${df['High'].max():.2f}\")\n",
    "print(f\"  All-Time Low: ${df['Low'].min():.2f}\")\n",
    "print(f\"  Average Close: ${df['Close'].mean():.2f}\")\n",
    "print(f\"  Volatility (Std): ${df['Close'].std():.2f}\")\n",
    "print(f\"  Total Return: {((df['Close'].iloc[-1] / df['Close'].iloc[0]) - 1) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualizer\n",
    "viz = StockVisualizer()\n",
    "\n",
    "# Plot stock price history\n",
    "viz.plot_stock_price(df, TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume and price analysis\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "# Price chart\n",
    "ax1.plot(df.index, df['Close'], label='Close Price', color='blue', linewidth=2)\n",
    "ax1.fill_between(df.index, df['Low'], df['High'], alpha=0.3, color='lightblue')\n",
    "ax1.set_title(f'{TICKER} - Price History ({PERIOD})', fontsize=16, fontweight='bold')\n",
    "ax1.set_ylabel('Price ($)', fontsize=12)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Volume chart\n",
    "ax2.bar(df.index, df['Volume'], color='green', alpha=0.6)\n",
    "ax2.set_title('Trading Volume', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Volume', fontsize=12)\n",
    "ax2.set_xlabel('Date', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_eng",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "Creating 40+ technical indicators for better prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features\n",
    "print(\"ğŸ”§ Engineering features...\\n\")\n",
    "engineer = FeatureEngineer(df)\n",
    "engineer.add_all_features()\n",
    "features_df = engineer.get_feature_dataframe()\n",
    "feature_names = engineer.get_feature_names()\n",
    "\n",
    "print(f\"âœ… Feature engineering complete!\")\n",
    "print(f\"ğŸ“Š Features created: {len(feature_names)}\")\n",
    "print(f\"ğŸ“ Dataset shape: {features_df.shape}\")\n",
    "print(f\"\\nğŸ“ Feature List:\")\n",
    "for i, feat in enumerate(feature_names, 1):\n",
    "    print(f\"  {i}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"ğŸ” Checking data quality...\\n\")\n",
    "missing_before = features_df.isnull().sum().sum()\n",
    "features_df = features_df.dropna()\n",
    "missing_after = features_df.isnull().sum().sum()\n",
    "\n",
    "print(f\"  Missing values before: {missing_before}\")\n",
    "print(f\"  Missing values after: {missing_after}\")\n",
    "print(f\"  Final dataset shape: {features_df.shape}\")\n",
    "print(f\"\\nâœ… Data is clean and ready for modeling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_indicators",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize key technical indicators\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "# Price with Moving Averages\n",
    "axes[0].plot(features_df.index, features_df['Close'], label='Close Price', linewidth=2)\n",
    "axes[0].plot(features_df.index, features_df['SMA_20'], label='SMA 20', linestyle='--', alpha=0.7)\n",
    "axes[0].plot(features_df.index, features_df['SMA_50'], label='SMA 50', linestyle='--', alpha=0.7)\n",
    "axes[0].set_title('Price with Moving Averages', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# RSI\n",
    "axes[1].plot(features_df.index, features_df['RSI'], label='RSI', color='purple', linewidth=2)\n",
    "axes[1].axhline(y=70, color='r', linestyle='--', label='Overbought (70)')\n",
    "axes[1].axhline(y=30, color='g', linestyle='--', label='Oversold (30)')\n",
    "axes[1].set_title('Relative Strength Index (RSI)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('RSI')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# MACD\n",
    "axes[2].plot(features_df.index, features_df['MACD'], label='MACD', linewidth=2)\n",
    "axes[2].plot(features_df.index, features_df['MACD_Signal'], label='Signal', linewidth=2)\n",
    "axes[2].bar(features_df.index, features_df['MACD_Histogram'], label='Histogram', alpha=0.3)\n",
    "axes[2].set_title('MACD Indicator', fontsize=14, fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepare_data",
   "metadata": {},
   "source": [
    "## 6. Prepare Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = features_df[feature_names].values\n",
    "y = features_df['Target'].values\n",
    "\n",
    "# Time series split (no shuffling)\n",
    "split_idx = int(len(X) * (1 - TEST_SIZE))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Get dates for test set\n",
    "test_dates = features_df.index[split_idx:]\n",
    "\n",
    "print(\"ğŸ“Š Data Split Summary:\")\n",
    "print(f\"  Total samples: {len(X)}\")\n",
    "print(f\"  Training samples: {len(X_train)} ({(1-TEST_SIZE)*100:.0f}%)\")\n",
    "print(f\"  Test samples: {len(X_test)} ({TEST_SIZE*100:.0f}%)\")\n",
    "print(f\"  Features: {len(feature_names)}\")\n",
    "print(f\"  Train date range: {features_df.index[0]} to {features_df.index[split_idx-1]}\")\n",
    "print(f\"  Test date range: {test_dates[0]} to {test_dates[-1]}\")\n",
    "print(f\"\\nâœ… Data prepared for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "models",
   "metadata": {},
   "source": [
    "## 7. Train Multiple ML Models\n",
    "\n",
    "Training 8 different models to maximize prediction accuracy and provide ensemble predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store models and results\n",
    "models = {}\n",
    "predictions = {}\n",
    "metrics = {}\n",
    "\n",
    "# Define all models\n",
    "model_configs = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0, random_state=RANDOM_STATE),\n",
    "    'Lasso Regression': Lasso(alpha=0.1, random_state=RANDOM_STATE),\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=N_ESTIMATORS, \n",
    "        max_depth=20, \n",
    "        random_state=RANDOM_STATE, \n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'XGBoost': xgb.XGBRegressor(\n",
    "        n_estimators=N_ESTIMATORS, \n",
    "        learning_rate=0.1, \n",
    "        max_depth=7, \n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=N_ESTIMATORS, \n",
    "        learning_rate=0.1, \n",
    "        max_depth=5, \n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'Extra Trees': ExtraTreesRegressor(\n",
    "        n_estimators=N_ESTIMATORS, \n",
    "        max_depth=20, \n",
    "        random_state=RANDOM_STATE, \n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'AdaBoost': AdaBoostRegressor(\n",
    "        n_estimators=100, \n",
    "        learning_rate=0.1, \n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"ğŸ¤– Training 8 ML Models...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, model in model_configs.items():\n",
    "    print(f\"\\nğŸ”„ Training {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    \n",
    "    # Store results\n",
    "    models[name] = model\n",
    "    predictions[name] = y_pred\n",
    "    metrics[name] = {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "    \n",
    "    print(f\"  âœ… {name} trained!\")\n",
    "    print(f\"     RÂ² Score: {r2:.4f}\")\n",
    "    print(f\"     RMSE: ${rmse:.2f}\")\n",
    "    print(f\"     MAE: ${mae:.2f}\")\n",
    "    print(f\"     MAPE: {mape:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… All models trained successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare_models",
   "metadata": {},
   "source": [
    "## 8. Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metrics_table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metrics comparison dataframe\n",
    "metrics_df = pd.DataFrame(metrics).T\n",
    "metrics_df = metrics_df.sort_values('R2', ascending=False)\n",
    "\n",
    "print(\"\\nğŸ“Š MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(metrics_df.to_string())\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find best model\n",
    "best_model_name = metrics_df.index[0]\n",
    "best_r2 = metrics_df.loc[best_model_name, 'R2']\n",
    "\n",
    "print(f\"\\nğŸ† BEST MODEL: {best_model_name}\")\n",
    "print(f\"   RÂ² Score: {best_r2:.4f}\")\n",
    "print(f\"   RMSE: ${metrics_df.loc[best_model_name, 'RMSE']:.2f}\")\n",
    "print(f\"   MAE: ${metrics_df.loc[best_model_name, 'MAE']:.2f}\")\n",
    "print(f\"   MAPE: {metrics_df.loc[best_model_name, 'MAPE']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# RÂ² Score\n",
    "metrics_df['R2'].plot(kind='barh', ax=axes[0, 0], color='skyblue')\n",
    "axes[0, 0].set_title('RÂ² Score (Higher is Better)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('RÂ² Score')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE\n",
    "metrics_df['RMSE'].plot(kind='barh', ax=axes[0, 1], color='salmon')\n",
    "axes[0, 1].set_title('RMSE (Lower is Better)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('RMSE ($)')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "metrics_df['MAE'].plot(kind='barh', ax=axes[1, 0], color='lightgreen')\n",
    "axes[1, 0].set_title('MAE (Lower is Better)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('MAE ($)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAPE\n",
    "metrics_df['MAPE'].plot(kind='barh', ax=axes[1, 1], color='plum')\n",
    "axes[1, 1].set_title('MAPE (Lower is Better)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('MAPE (%)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actual for all models\n",
    "fig, axes = plt.subplots(4, 2, figsize=(16, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, y_pred) in enumerate(predictions.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    ax.plot(test_dates, y_test, label='Actual', linewidth=2, color='blue', alpha=0.7)\n",
    "    ax.plot(test_dates, y_pred, label='Predicted', linewidth=2, color='red', alpha=0.7, linestyle='--')\n",
    "    \n",
    "    r2 = metrics[name]['R2']\n",
    "    ax.set_title(f'{name} (RÂ²={r2:.4f})', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Price ($)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ensemble",
   "metadata": {},
   "source": [
    "## 9. Ensemble Prediction\n",
    "\n",
    "Combining all models using weighted average based on RÂ² scores for more robust predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ensemble_pred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weights based on RÂ² scores (higher RÂ² = more weight)\n",
    "r2_scores = np.array([metrics[name]['R2'] for name in predictions.keys()])\n",
    "r2_scores = np.maximum(r2_scores, 0)  # Ensure non-negative\n",
    "weights = r2_scores / r2_scores.sum()  # Normalize to sum to 1\n",
    "\n",
    "# Calculate weighted ensemble prediction\n",
    "ensemble_pred = np.zeros(len(y_test))\n",
    "for name, y_pred in predictions.items():\n",
    "    weight = weights[list(predictions.keys()).index(name)]\n",
    "    ensemble_pred += weight * y_pred\n",
    "\n",
    "# Calculate ensemble metrics\n",
    "ensemble_rmse = np.sqrt(mean_squared_error(y_test, ensemble_pred))\n",
    "ensemble_mae = mean_absolute_error(y_test, ensemble_pred)\n",
    "ensemble_r2 = r2_score(y_test, ensemble_pred)\n",
    "ensemble_mape = np.mean(np.abs((y_test - ensemble_pred) / y_test)) * 100\n",
    "\n",
    "print(\"ğŸ¯ ENSEMBLE MODEL PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nModel Weights (based on RÂ² scores):\")\n",
    "for name, weight in zip(predictions.keys(), weights):\n",
    "    print(f\"  {name}: {weight:.4f} ({weight*100:.2f}%)\")\n",
    "    \n",
    "print(\"\\nEnsemble Metrics:\")\n",
    "print(f\"  RÂ² Score: {ensemble_r2:.4f}\")\n",
    "print(f\"  RMSE: ${ensemble_rmse:.2f}\")\n",
    "print(f\"  MAE: ${ensemble_mae:.2f}\")\n",
    "print(f\"  MAPE: {ensemble_mape:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ensemble prediction\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.plot(test_dates, y_test, label='Actual Price', linewidth=2.5, color='blue')\n",
    "plt.plot(test_dates, ensemble_pred, label='Ensemble Prediction', linewidth=2.5, color='red', linestyle='--')\n",
    "\n",
    "# Add confidence band\n",
    "std_pred = np.std([predictions[name] for name in predictions.keys()], axis=0)\n",
    "plt.fill_between(test_dates, \n",
    "                 ensemble_pred - std_pred, \n",
    "                 ensemble_pred + std_pred, \n",
    "                 alpha=0.2, color='red', label='Prediction Uncertainty')\n",
    "\n",
    "plt.title(f'{TICKER} - Ensemble Model Prediction (RÂ²={ensemble_r2:.4f})', \n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price ($)', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_importance",
   "metadata": {},
   "source": [
    "## 10. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_imp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from tree-based models\n",
    "tree_models = ['Random Forest', 'XGBoost', 'Gradient Boosting', 'Extra Trees']\n",
    "importance_data = []\n",
    "\n",
    "for model_name in tree_models:\n",
    "    if model_name in models:\n",
    "        importances = models[model_name].feature_importances_\n",
    "        importance_data.append(importances)\n",
    "\n",
    "# Average importance across all tree models\n",
    "avg_importance = np.mean(importance_data, axis=0)\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': avg_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Display top 20 features\n",
    "print(\"\\nğŸ” TOP 20 MOST IMPORTANT FEATURES\")\n",
    "print(\"=\"*60)\n",
    "print(feature_importance_df.head(20).to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_feature_imp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 15 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance_df.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['Importance'], color='teal')\n",
    "plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "plt.xlabel('Average Importance', fontsize=12)\n",
    "plt.title('Top 15 Most Important Features', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prediction",
   "metadata": {},
   "source": [
    "## 11. Next-Day Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "next_day_pred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the latest data point for prediction\n",
    "latest_features = features_df[feature_names].iloc[-1:].values\n",
    "latest_features_scaled = scaler.transform(latest_features)\n",
    "\n",
    "# Predict with all models\n",
    "next_day_predictions = {}\n",
    "print(\"\\nğŸ”® NEXT-DAY PRICE PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, model in models.items():\n",
    "    pred = model.predict(latest_features_scaled)[0]\n",
    "    next_day_predictions[name] = pred\n",
    "    print(f\"  {name}: ${pred:.2f}\")\n",
    "\n",
    "# Ensemble prediction for next day\n",
    "ensemble_next_day = np.sum([next_day_predictions[name] * weights[idx] \n",
    "                             for idx, name in enumerate(predictions.keys())])\n",
    "\n",
    "current_price = features_df['Close'].iloc[-1]\n",
    "predicted_change = ((ensemble_next_day - current_price) / current_price) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ“Š Current Price: ${current_price:.2f}\")\n",
    "print(f\"ğŸ¯ Ensemble Prediction: ${ensemble_next_day:.2f}\")\n",
    "print(f\"ğŸ“ˆ Predicted Change: {predicted_change:+.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signals",
   "metadata": {},
   "source": [
    "## 12. ğŸ¯ BUY/SELL SIGNAL GENERATION\n",
    "\n",
    "### This is what you need for paper trading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate_signals",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prediction agreement\n",
    "predictions_array = np.array(list(next_day_predictions.values()))\n",
    "pred_changes = ((predictions_array - current_price) / current_price) * 100\n",
    "\n",
    "# Count bullish and bearish predictions\n",
    "bullish_count = np.sum(pred_changes > 0)\n",
    "bearish_count = np.sum(pred_changes < 0)\n",
    "total_models = len(predictions_array)\n",
    "\n",
    "# Calculate confidence\n",
    "bullish_confidence = bullish_count / total_models\n",
    "bearish_confidence = bearish_count / total_models\n",
    "\n",
    "# Generate signal\n",
    "if predicted_change > BUY_THRESHOLD and bullish_confidence >= CONFIDENCE_THRESHOLD:\n",
    "    signal = \"ğŸŸ¢ STRONG BUY\"\n",
    "    signal_color = 'green'\n",
    "    action = \"BUY\"\n",
    "elif predicted_change > 0 and bullish_confidence >= 0.5:\n",
    "    signal = \"ğŸŸ¢ BUY\"\n",
    "    signal_color = 'lightgreen'\n",
    "    action = \"BUY\"\n",
    "elif predicted_change < SELL_THRESHOLD and bearish_confidence >= CONFIDENCE_THRESHOLD:\n",
    "    signal = \"ğŸ”´ STRONG SELL\"\n",
    "    signal_color = 'red'\n",
    "    action = \"SELL\"\n",
    "elif predicted_change < 0 and bearish_confidence >= 0.5:\n",
    "    signal = \"ğŸ”´ SELL\"\n",
    "    signal_color = 'lightcoral'\n",
    "    action = \"SELL\"\n",
    "else:\n",
    "    signal = \"ğŸŸ¡ HOLD\"\n",
    "    signal_color = 'yellow'\n",
    "    action = \"HOLD\"\n",
    "\n",
    "# Calculate position size based on confidence\n",
    "max_confidence = max(bullish_confidence, bearish_confidence)\n",
    "position_size_pct = max_confidence * 100\n",
    "\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"#\" + \" \"*78 + \"#\")\n",
    "print(\"#\" + \" \"*20 + \"ğŸ¯ TRADING RECOMMENDATION FOR PAPER TRADING ğŸ¯\" + \" \"*12 + \"#\")\n",
    "print(\"#\" + \" \"*78 + \"#\")\n",
    "print(\"#\"*80)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"ğŸ“Š Stock: {TICKER}\")\n",
    "print(f\"ğŸ“… Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"ğŸ’° Current Price: ${current_price:.2f}\")\n",
    "print(f\"ğŸ¯ Predicted Price: ${ensemble_next_day:.2f}\")\n",
    "print(f\"ğŸ“ˆ Expected Change: {predicted_change:+.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(f\"\\nâš¡ RECOMMENDATION: {signal}\")\n",
    "print(f\"   Action: {action}\")\n",
    "print(f\"   Confidence: {max_confidence*100:.1f}%\")\n",
    "print(f\"   Position Size: {position_size_pct:.1f}% of capital\")\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "\n",
    "print(\"\\nğŸ“Š Model Agreement:\")\n",
    "print(f\"   Bullish models: {bullish_count}/{total_models} ({bullish_confidence*100:.1f}%)\")\n",
    "print(f\"   Bearish models: {bearish_count}/{total_models} ({bearish_confidence*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nğŸ“ Individual Model Predictions:\")\n",
    "for name, pred in next_day_predictions.items():\n",
    "    change = ((pred - current_price) / current_price) * 100\n",
    "    direction = \"ğŸ“ˆ\" if change > 0 else \"ğŸ“‰\"\n",
    "    print(f\"   {direction} {name}: ${pred:.2f} ({change:+.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nğŸ’¡ PAPER TRADING INSTRUCTIONS:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if action == \"BUY\":\n",
    "    print(f\"\\n1. Open your paper trading account (TradingView, Webull, etc.)\")\n",
    "    print(f\"2. Place a BUY order for {TICKER}\")\n",
    "    print(f\"3. Suggested position: {position_size_pct:.0f}% of available capital\")\n",
    "    print(f\"4. Entry price target: ~${current_price:.2f}\")\n",
    "    print(f\"5. Target exit price: ${ensemble_next_day:.2f} ({predicted_change:+.2f}%)\")\n",
    "    print(f\"6. Stop-loss: ${current_price * 0.98:.2f} (-2%)\")\n",
    "    print(f\"7. Take-profit: ${current_price * 1.05:.2f} (+5%)\")\n",
    "    \n",
    "elif action == \"SELL\":\n",
    "    print(f\"\\n1. If you own {TICKER}, consider selling\")\n",
    "    print(f\"2. Open your paper trading account\")\n",
    "    print(f\"3. Place a SELL order for your {TICKER} position\")\n",
    "    print(f\"4. Or open a SHORT position if allowed ({position_size_pct:.0f}% of capital)\")\n",
    "    print(f\"5. Entry price: ~${current_price:.2f}\")\n",
    "    print(f\"6. Exit target: ${ensemble_next_day:.2f}\")\n",
    "    \n",
    "else:  # HOLD\n",
    "    print(f\"\\n1. No strong signal detected\")\n",
    "    print(f\"2. Keep your current positions\")\n",
    "    print(f\"3. Wait for a clearer signal (>70% model agreement)\")\n",
    "    print(f\"4. Monitor the stock and re-run this analysis tomorrow\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âš ï¸  RISK DISCLAIMER:\")\n",
    "print(\"   - This is for PAPER TRADING only (fake money)\")\n",
    "print(\"   - Past performance does not guarantee future results\")\n",
    "print(\"   - Stock predictions are probabilistic, not certain\")\n",
    "print(f\"   - Model accuracy (RÂ²): {ensemble_r2:.2%}\")\n",
    "print(f\"   - Average prediction error (MAPE): {ensemble_mape:.2f}%\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal_visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the trading signal\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Price prediction chart\n",
    "last_30_days = features_df['Close'].iloc[-30:]\n",
    "dates_30 = features_df.index[-30:]\n",
    "next_date = dates_30[-1] + timedelta(days=1)\n",
    "\n",
    "ax1.plot(dates_30, last_30_days, 'b-', linewidth=2, label='Historical Price')\n",
    "ax1.plot([dates_30[-1], next_date], [current_price, ensemble_next_day], \n",
    "         'r--', linewidth=2, marker='o', markersize=10, label='Prediction')\n",
    "ax1.axhline(y=current_price, color='gray', linestyle=':', alpha=0.5)\n",
    "ax1.fill_between([dates_30[-1], next_date], \n",
    "                  [current_price, ensemble_next_day], \n",
    "                  alpha=0.3, color=signal_color)\n",
    "ax1.set_title(f'{TICKER} - Price Prediction & Signal', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Price ($)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.text(next_date, ensemble_next_day, f\"  ${ensemble_next_day:.2f}\\n  {signal}\", \n",
    "         fontsize=10, fontweight='bold', va='center')\n",
    "\n",
    "# Model agreement pie chart\n",
    "labels = ['Bullish', 'Bearish']\n",
    "sizes = [bullish_count, bearish_count]\n",
    "colors = ['lightgreen', 'lightcoral']\n",
    "explode = (0.1 if bullish_count > bearish_count else 0, \n",
    "           0.1 if bearish_count > bullish_count else 0)\n",
    "\n",
    "ax2.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "ax2.set_title(f'Model Agreement\\n(Confidence: {max_confidence*100:.1f}%)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 13. ğŸ“Š Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" \"*25 + \"ğŸ“Š ANALYSIS SUMMARY ğŸ“Š\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Stock: {TICKER} - {info.get('name', 'Google')}\")\n",
    "print(f\"ğŸ“… Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"ğŸ“Š Data Period: {PERIOD}\")\n",
    "print(f\"ğŸ“ Total Data Points: {len(features_df)}\")\n",
    "print(f\"ğŸ”§ Features Created: {len(feature_names)}\")\n",
    "\n",
    "print(f\"\\nğŸ’° Price Information:\")\n",
    "print(f\"   Current Price: ${current_price:.2f}\")\n",
    "print(f\"   Predicted Price (Next Day): ${ensemble_next_day:.2f}\")\n",
    "print(f\"   Expected Change: {predicted_change:+.2f}%\")\n",
    "print(f\"   52-Week High: ${df['High'].iloc[-252:].max():.2f}\")\n",
    "print(f\"   52-Week Low: ${df['Low'].iloc[-252:].min():.2f}\")\n",
    "\n",
    "print(f\"\\nğŸ¤– Models Trained: {len(models)}\")\n",
    "print(f\"   1. Linear Regression\")\n",
    "print(f\"   2. Ridge Regression\")\n",
    "print(f\"   3. Lasso Regression\")\n",
    "print(f\"   4. Random Forest\")\n",
    "print(f\"   5. XGBoost\")\n",
    "print(f\"   6. Gradient Boosting\")\n",
    "print(f\"   7. Extra Trees\")\n",
    "print(f\"   8. AdaBoost\")\n",
    "\n",
    "print(f\"\\nğŸ† Best Individual Model: {best_model_name}\")\n",
    "print(f\"   RÂ² Score: {best_r2:.4f}\")\n",
    "print(f\"   MAPE: {metrics_df.loc[best_model_name, 'MAPE']:.2f}%\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Ensemble Model Performance:\")\n",
    "print(f\"   RÂ² Score: {ensemble_r2:.4f}\")\n",
    "print(f\"   RMSE: ${ensemble_rmse:.2f}\")\n",
    "print(f\"   MAE: ${ensemble_mae:.2f}\")\n",
    "print(f\"   MAPE: {ensemble_mape:.2f}%\")\n",
    "\n",
    "print(f\"\\nâš¡ TRADING SIGNAL: {signal}\")\n",
    "print(f\"   Recommended Action: {action}\")\n",
    "print(f\"   Confidence Level: {max_confidence*100:.1f}%\")\n",
    "print(f\"   Bullish Models: {bullish_count}/{total_models}\")\n",
    "print(f\"   Bearish Models: {bearish_count}/{total_models}\")\n",
    "\n",
    "print(\"\\nğŸ” Top 5 Important Features:\")\n",
    "for i, row in feature_importance_df.head(5).iterrows():\n",
    "    print(f\"   {i+1}. {row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nâœ… Analysis Complete! Use the recommendation above for paper trading.\")\n",
    "print(\"\\nğŸ’¡ Pro Tips:\")\n",
    "print(\"   â€¢ Always use stop-loss orders to limit losses\")\n",
    "print(\"   â€¢ Never invest more than you can afford to lose\")\n",
    "print(\"   â€¢ Paper trade for at least 3-6 months before using real money\")\n",
    "print(\"   â€¢ Diversify your portfolio across multiple stocks\")\n",
    "print(\"   â€¢ Re-run this analysis daily for updated signals\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps",
   "metadata": {},
   "source": [
    "## ğŸ¯ What to Do Next?\n",
    "\n",
    "### For Paper Trading:\n",
    "\n",
    "1. **Open a Paper Trading Account**\n",
    "   - TradingView (free)\n",
    "   - Webull (paper trading mode)\n",
    "   - TD Ameritrade thinkorswim\n",
    "\n",
    "2. **Follow the Recommendation**\n",
    "   - Use the BUY/SELL/HOLD signal from Section 12\n",
    "   - Set the suggested stop-loss and take-profit levels\n",
    "   - Track your trades in a spreadsheet\n",
    "\n",
    "3. **Run Daily**\n",
    "   - Re-run this notebook every day before market open\n",
    "   - Adjust your positions based on new signals\n",
    "   - Track your win rate and performance\n",
    "\n",
    "4. **After 100+ Trades (3-6 months)**\n",
    "   - Calculate your total return\n",
    "   - If profitable and consistent, consider real trading with small amounts\n",
    "   - If not profitable, improve the model or strategy\n",
    "\n",
    "### To Improve This Model:\n",
    "\n",
    "1. **Add More Data Sources**\n",
    "   - Sentiment analysis from news/Twitter\n",
    "   - Economic indicators (interest rates, GDP)\n",
    "   - Competitor stock prices\n",
    "\n",
    "2. **Try Different Features**\n",
    "   - More technical indicators\n",
    "   - Market breadth indicators\n",
    "   - Sector performance\n",
    "\n",
    "3. **Advanced Techniques**\n",
    "   - LSTM neural networks for sequences\n",
    "   - Transformer models\n",
    "   - Reinforcement learning for trading strategy\n",
    "\n",
    "### âš ï¸ Important Reminders:\n",
    "\n",
    "- ğŸ“Š **This is NOT financial advice**\n",
    "- ğŸ“ **Educational purposes only**\n",
    "- ğŸ’° **Use paper trading first** (at least 6 months)\n",
    "- ğŸ“‰ **Past performance â‰  future results**\n",
    "- ğŸ›¡ï¸ **Always use risk management** (stop-loss, position sizing)\n",
    "- ğŸ“ˆ **Even 60% accuracy can lose money** (due to fees and slippage)\n",
    "\n",
    "Good luck with your paper trading! ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
